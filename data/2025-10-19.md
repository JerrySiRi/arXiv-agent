<div id=toc></div>

# Table of Contents

- [cs.LO](#cs.LO) [Total: 4]
- [cs.MA](#cs.MA) [Total: 4]


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [1] [T-BAT semantics and its logics](https://arxiv.org/abs/2510.14361)
*Pawel Pawlowski*

Main category: cs.LO

TL;DR: 本文研究了T-BAT逻辑的四值非确定性语义，这是一种表达非形式可证性概念的形式系统。论文分析了语义弱化和强化与所诱导公理之间的相互作用，证明了该语义中所有可定义逻辑的完备性，并提供了T-BAT逻辑的直观公理化。


<details>
  <summary>Details</summary>
Motivation: 研究T-BAT逻辑的四值非确定性语义，探索语义变化与公理之间的复杂关系，并为该逻辑提供直观的公理化系统。

Method: 通过将真值转换为对象语言中的特定表达式来证明语义中所有可定义逻辑的完备性，同时利用克里普克语义从模态角度分析公理，提供它们诱导的框架条件。

Result: 证明了T-BAT语义中所有可定义逻辑的完备性，分析了语义弱化/强化与诱导公理之间的相互作用，并提供了该逻辑的直观公理化。

Conclusion: T-BAT逻辑的四值非确定性语义能够有效表达非形式可证性概念，通过语义变换和模态分析可以建立完整的逻辑系统并实现直观的公理化。

Abstract: \textbf{T-BAT} logic is a formal system designed to express the notion of
informal provability. This type of provability is closely related to
mathematical practice and is quite often contrasted with formal provability,
understood as a formal derivation in an appropriate formal system.
\textbf{T-BAT} is a non-deterministic four-valued logic. The logical values in
\textbf{T-BAT} semantics convey not only the information whether a given
formula is true but also about its provability status.
  The primary aim of our paper is to study the proposed four-valued
non-deterministic semantics. We look into the intricacies of the interactions
between various weakenings and strengthenings of the semantics with axioms that
they induce. We prove the completeness of all the logics that are definable in
this semantics by transforming truth values into specific expressions
formulated within the object language of the semantics. Additionally, we
utilize Kripke semantics to examine these axioms from a modal perspective by
providing a frame condition that they induce. The secondary aim of this paper
is to provide an intuitive axiomatization of \textbf{T-BAT} logic.

</details>


### [2] [Optimization Modulo Integer Linear-Exponential Programs](https://arxiv.org/abs/2510.14550)
*S Hitarth,Alessio Mansutti,Guruprerana Shabadi*

Main category: cs.LO

TL;DR: 本文首次研究了整数线性指数规划的优化问题复杂性，该问题在经典整数线性规划基础上扩展了指数函数和取模函数。证明了最优解可以用整数线性指数直线程序（ILESLP）简洁表示，并给出了在整数分解预言机下的多项式时间验证算法。


<details>
  <summary>Details</summary>
Motivation: 研究整数线性指数规划的优化问题复杂性，这类问题扩展了经典整数线性规划，包含指数函数和取模函数，其决策问题已被证明是NP完全的。

Method: 提出整数线性指数直线程序（ILESLP）作为最优解的表示形式，开发了在整数分解预言机下的多项式时间验证算法，用于检查ILESLP是否编码了可行解并比较目标函数值。

Result: 证明了最优解可以用ILESLP简洁表示；给出了多项式时间验证算法（需整数分解预言机）；将优化问题置于扩展的NPO类中，位于FNP^NP内。

Conclusion: 整数线性指数规划的优化问题具有结构良好的最优解表示，在适当计算模型下可实现高效验证，为这类复杂优化问题的理论研究提供了新框架。

Abstract: This paper presents the first study of the complexity of the optimization
problem for integer linear-exponential programs which extend classical integer
linear programs with the exponential function $x \mapsto 2^x$ and the remainder
function ${(x,y) \mapsto (x \bmod 2^y)}$. The problem of deciding if such a
program has a solution was recently shown to be NP-complete in [Chistikov et
al., ICALP'24]. The optimization problem instead asks for a solution that
maximizes (or minimizes) a linear-exponential objective function, subject to
the constraints of an integer linear-exponential program. We establish the
following results:
  1. If an optimal solution exists, then one of them can be succinctly
represented as an integer linear-exponential straight-line program (ILESLP): an
arithmetic circuit whose gates always output an integer value (by construction)
and implement the operations of addition, exponentiation, and multiplication by
rational numbers.
  2. There is an algorithm that runs in polynomial time, given access to an
integer factoring oracle, which determines whether an ILESLP encodes a solution
to an integer linear-exponential program. This algorithm can also be used to
compare the values taken by the objective function on two given solutions.
  Building on these results, we place the optimization problem for integer
linear-exponential programs within an extension of the optimization class
$\text{NPO}$ that lies within $\text{FNP}^{\text{NP}}$. In essence, this
extension forgoes determining the optimal solution via binary search.

</details>


### [3] [Problems and Consequences of Bilateral Notions of (Meta-)Derivability](https://arxiv.org/abs/2510.14619)
*Sara Ayhan*

Main category: cs.LO

TL;DR: 本文探讨了双边主义证明论语义学在序列演算中的实现问题，指出在序列演算中需要同时双重化序列符号和水平线，这揭示了证明与反驳概念之间的不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 研究双边主义证明论语义学在序列演算表示中面临的挑战，特别是如何同时双重化序列符号和水平线这两个推导关系，以保持证明与反驳之间的平衡。

Method: 分析序列演算中的两个推导关系（序列符号和水平线），探讨双重化这些关系时遇到的问题，并提出可能的解决方案来保持双边主义所需的平衡。

Result: 发现序列演算中水平线的双重化比自然演绎中更复杂，揭示了证明与反驳概念之间的深层不平衡问题。

Conclusion: 序列演算中实现真正的双边主义需要解决证明与反驳之间的概念不平衡问题，本文分析了问题的根源并提出了可能的解决方案。

Abstract: A bilateralist take on proof-theoretic semantics can be understood as
demanding of a proof system to display not only rules giving the connectives'
provability conditions but also their refutability conditions. On such a view,
then, a system with two derivability relations is obtained, which can be quite
naturally expressed in a proof system of natural deduction but which faces
obstacles in a sequent calculus representation. Since in a sequent calculus
there are two derivability relations inherent, one expressed by the sequent
sign and one by the horizontal lines holding between sequents, in a truly
bilateral calculus both need to be dualized. While dualizing the sequent sign
is rather straightforwardly corresponding to dualizing the horizontal lines in
natural deduction, dualizing the horizontal lines in sequent calculus, uncovers
problems that, as will be argued in this paper, shed light on deeper conceptual
issues concerning an imbalance between the notions of proof vs. refutation. The
roots of this problem will be further analyzed and possible solutions on how to
retain a bilaterally desired balance in our system are presented.

</details>


### [4] [Admissibility of Substitution Rule in Cyclic-Proof Systems](https://arxiv.org/abs/2510.14749)
*Kenji Saotome,Koji Nakazawa*

Main category: cs.LO

TL;DR: 本文证明了在包含切割规则的CLKID^ω循环证明系统中替换规则的可接纳性，通过将循环证明展开为无穷形式、提升替换规则并重新放置回边来构造不含替换规则的循环证明。


<details>
  <summary>Details</summary>
Motivation: 替换规则在循环证明系统中增加了理论案例分析复杂性和证明搜索的计算成本，因此其可接纳性在理论和计算层面都值得追求。

Method: 采用将循环证明展开为无穷形式的方法，提升替换规则并重新放置回边，从而构造不含替换规则的循环证明。当限制替换不包含函数符号时，该方法可扩展到更广泛的系统。

Result: 证明了在包含切割规则的CLKID^ω循环证明系统中替换规则是可接纳的，且当限制替换不包含函数符号时，该结果可扩展到无切割CLKID^ω和分离逻辑的循环证明系统。

Conclusion: 通过创新的证明转换技术，成功解决了循环证明系统中替换规则的可接纳性问题，为循环证明理论提供了重要进展。

Abstract: This paper investigates the admissibility of the substitution rule in
cyclic-proof systems. The substitution rule complicates theoretical case
analysis and increases computational cost in proof search since every sequent
can be a conclusion of an instance of the substitution rule; hence,
admissibility is desirable on both fronts. While admissibility is often shown
by local proof transformations in non-cyclic systems, such transformations may
disrupt cyclic structure and do not readily apply. Prior remarks suggested that
the substitution rule is likely nonadmissible in the cyclic-proof system
CLKID^omega for first-order logic with inductive predicates. In this paper, we
prove admissibility in CLKID^omega, assuming the presence of the cut rule. Our
approach unfolds a cyclic proof into an infinitary form, lifts the substitution
rules, and places back edges to construct a cyclic proof without the
substitution rule. If we restrict substitutions to exclude function symbols,
the result extends to a broader class of systems, including cut-free
CLKID^omega and cyclic-proof systems for the separation logic.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [5] [Benefits and Limitations of Communication in Multi-Agent Reasoning](https://arxiv.org/abs/2510.13903)
*Michael Rizvi-Martel,Satwik Bhattamishra,Neil Rathi,Guillaume Rabusseau,Michael Hahn*

Main category: cs.MA

TL;DR: 本文提出了一个理论框架来分析多智能体系统的表达能力，研究了状态跟踪、回忆和k跳推理三种算法家族，推导了所需智能体数量、通信结构和可实现加速的界限，并通过实验验证了理论预测。


<details>
  <summary>Details</summary>
Motivation: 随着问题复杂性和上下文长度的增加，链式思维提示在大型语言模型中的性能会下降。多智能体范式通过将复杂任务分解为更短、更易管理的任务提供了有前景的解决方案，但这类系统的基本能力尚未得到充分理解。

Method: 提出理论框架分析多智能体系统的表达能力，应用于状态跟踪、回忆和k跳推理三种算法家族，推导智能体数量、通信结构和加速界限，并通过预训练LLM在受控合成基准上进行实验验证。

Result: 理论分析确定了通信有益的制度，划定了智能体数量和带宽之间的权衡，并揭示了当任一资源受限时的内在限制。实验结果证实了理论预测的关键数量之间的权衡关系。

Conclusion: 该分析为设计可扩展的多智能体推理系统提供了原则性指导，揭示了多智能体系统在不同资源约束下的表现特征和优化方向。

Abstract: Chain-of-thought prompting has popularized step-by-step reasoning in large
language models, yet model performance still degrades as problem complexity and
context length grow. By decomposing difficult tasks with long contexts into
shorter, manageable ones, recent multi-agent paradigms offer a promising
near-term solution to this problem. However, the fundamental capacities of such
systems are poorly understood. In this work, we propose a theoretical framework
to analyze the expressivity of multi-agent systems. We apply our framework to
three algorithmic families: state tracking, recall, and $k$-hop reasoning. We
derive bounds on (i) the number of agents required to solve the task exactly,
(ii) the quantity and structure of inter-agent communication, and (iii) the
achievable speedups as problem size and context scale. Our results identify
regimes where communication is provably beneficial, delineate tradeoffs between
agent count and bandwidth, and expose intrinsic limitations when either
resource is constrained. We complement our theoretical analysis with a set of
experiments on pretrained LLMs using controlled synthetic benchmarks. Empirical
outcomes confirm the tradeoffs between key quantities predicted by our theory.
Collectively, our analysis offers principled guidance for designing scalable
multi-agent reasoning systems.

</details>


### [6] [Static Sandboxes Are Inadequate: Modeling Societal Complexity Requires Open-Ended Co-Evolution in LLM-Based Multi-Agent Simulations](https://arxiv.org/abs/2510.13982)
*Jinkun Chen,Sher Badshah,Xuemin Yu,Sijia Han,Jiechao Gao*

Main category: cs.MA

TL;DR: 本文主张超越静态基准，推动多智能体系统向开放、持续协同进化的方向发展，强调需要重新思考当前基于固定任务的评估范式，以捕捉真实社会复杂性。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的多智能体模拟大多局限于静态沙盒环境，无法充分模拟真实世界的动态性和复杂性，这限制了AI系统在开放环境中的适应能力和社会对齐研究。

Method: 通过批判性回顾结合LLM与多智能体动态的新兴架构，分析平衡稳定性与多样性、评估意外行为、扩展复杂性等关键挑战，并提出新的分类体系和研究路线图。

Result: 提出了以开放性、持续协同进化和构建有韧性的社会对齐AI生态系统为核心的研究路线图，呼吁社区超越静态范式。

Conclusion: 必须重新思考静态任务特定基准的适用性，推动下一代适应性、社会感知的多智能体模拟发展，重点关注开放性和持续协同进化。

Abstract: What if artificial agents could not just communicate, but also evolve, adapt,
and reshape their worlds in ways we cannot fully predict? With llm now powering
multi-agent systems and social simulations, we are witnessing new possibilities
for modeling open-ended, ever-changing environments. Yet, most current
simulations remain constrained within static sandboxes, characterized by
predefined tasks, limited dynamics, and rigid evaluation criteria. These
limitations prevent them from capturing the complexity of real-world societies.
In this paper, we argue that static, task-specific benchmarks are fundamentally
inadequate and must be rethought. We critically review emerging architectures
that blend llm with multi-agent dynamics, highlight key hurdles such as
balancing stability and diversity, evaluating unexpected behaviors, and scaling
to greater complexity, and introduce a fresh taxonomy for this rapidly evolving
field. Finally, we present a research roadmap centered on open-endedness,
continuous co-evolution, and the development of resilient, socially aligned AI
ecosystems. \textbf{We call on the community to move beyond static paradigms
and help shape the next generation of adaptive, socially-aware multi-agent
simulations.}

</details>


### [7] [Stop Reducing Responsibility in LLM-Powered Multi-Agent Systems to Local Alignment](https://arxiv.org/abs/2510.14008)
*Jinwei Hu,Yi Dong,Shuang Ao,Zhuoyun Li,Boxuan Wang,Lokesh Singh,Guangliang Cheng,Sarvapali D. Ramchurn,Xiaowei Huang*

Main category: cs.MA

TL;DR: 论文提出LLM驱动的多智能体系统需要从局部智能体对齐转向全局系统性协议，将责任视为涵盖协议、不确定性和安全性的全生命周期属性，需要主观人类价值观与客观可验证性的互补整合，以及结合跨学科设计和人机协作监管的双视角治理框架。


<details>
  <summary>Details</summary>
Motivation: LLM多智能体系统在分布式推理、协作和任务泛化方面具有巨大潜力，但也带来了协议不可保证、级联不确定性和对抗性漏洞等额外风险，需要确保系统负责任行为的新范式。

Method: 提出从局部智能体对齐到全局系统性协议的范式转变，将责任概念化为包含协议、不确定性和安全性的全生命周期属性，需要主观人类价值观与客观可验证性的整合，以及跨学科设计与人机协作监管的双视角治理框架。

Result: 将LLM多智能体系统视为统一的动态社会技术系统，需要原则性机制来支持责任的每个维度，实现伦理对齐、可验证一致性和弹性行为，以维持系统范围的持续协议。

Conclusion: 确保LLM多智能体系统负责任行为需要系统性方法，包括全局协议、生命周期责任管理和双视角治理，将系统视为统一的社会技术实体而非松散的智能体集合。

Abstract: LLM-powered Multi-Agent Systems (LLM-MAS) unlock new potentials in
distributed reasoning, collaboration, and task generalization but also
introduce additional risks due to unguaranteed agreement, cascading
uncertainty, and adversarial vulnerabilities. We argue that ensuring
responsible behavior in such systems requires a paradigm shift: from local,
superficial agent-level alignment to global, systemic agreement. We
conceptualize responsibility not as a static constraint but as a lifecycle-wide
property encompassing agreement, uncertainty, and security, each requiring the
complementary integration of subjective human-centered values and objective
verifiability. Furthermore, a dual-perspective governance framework that
combines interdisciplinary design with human-AI collaborative oversight is
essential for tracing and ensuring responsibility throughout the lifecycle of
LLM-MAS. Our position views LLM-MAS not as loose collections of agents, but as
unified, dynamic socio-technical systems that demand principled mechanisms to
support each dimension of responsibility and enable ethically aligned,
verifiably coherent, and resilient behavior for sustained, system-wide
agreement.

</details>


### [8] [The Role of Social Learning and Collective Norm Formation in Fostering Cooperation in LLM Multi-Agent Systems](https://arxiv.org/abs/2510.14401)
*Prateek Gupta,Qiankun Zhong,Hiromu Yakura,Thomas Eisenmann,Iyad Rahwan*

Main category: cs.MA

TL;DR: 本文提出了一个基于文化进化机制（社会学习和基于规范的惩罚）的公共资源池（CPR）模拟框架，该框架移除了显式奖励信号，使规范能够内生地出现。研究验证了模拟的有效性，并系统比较了不同LLM在维持合作和规范形成方面的表现差异。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数LLM系统在公共资源池游戏中为智能体提供与其行动直接相关的显式奖励函数，而人类合作往往在没有完全了解收益和群体的情况下出现，依赖于启发式、沟通和惩罚。本文旨在开发一个更接近人类合作机制的模拟框架。

Method: 引入一个CPR模拟框架，移除显式奖励信号，嵌入文化进化机制：社会学习（从成功同伴处采用策略和信念）和基于规范的惩罚（基于Ostrom的资源治理原则）。智能体通过环境反馈从收获、监控和惩罚的后果中学习，使规范内生出现。

Result: 研究结果揭示了不同LLM在维持合作和规范形成方面的系统性差异，该框架成为研究混合动机LLM社会中涌现规范的严格测试平台。

Conclusion: 该框架可指导AI系统在社会和组织环境中的设计，在这些环境中与合作规范的协调对于AI中介环境的稳定性、公平性和有效治理至关重要。

Abstract: A growing body of multi-agent studies with Large Language Models (LLMs)
explores how norms and cooperation emerge in mixed-motive scenarios, where
pursuing individual gain can undermine the collective good. While prior work
has explored these dynamics in both richly contextualized simulations and
simplified game-theoretic environments, most LLM systems featuring common-pool
resource (CPR) games provide agents with explicit reward functions directly
tied to their actions. In contrast, human cooperation often emerges without
full visibility into payoffs and population, relying instead on heuristics,
communication, and punishment. We introduce a CPR simulation framework that
removes explicit reward signals and embeds cultural-evolutionary mechanisms:
social learning (adopting strategies and beliefs from successful peers) and
norm-based punishment, grounded in Ostrom's principles of resource governance.
Agents also individually learn from the consequences of harvesting, monitoring,
and punishing via environmental feedback, enabling norms to emerge
endogenously. We establish the validity of our simulation by reproducing key
findings from existing studies on human behavior. Building on this, we examine
norm evolution across a $2\times2$ grid of environmental and social
initialisations (resource-rich vs. resource-scarce; altruistic vs. selfish) and
benchmark how agentic societies comprised of different LLMs perform under these
conditions. Our results reveal systematic model differences in sustaining
cooperation and norm formation, positioning the framework as a rigorous testbed
for studying emergent norms in mixed-motive LLM societies. Such analysis can
inform the design of AI systems deployed in social and organizational contexts,
where alignment with cooperative norms is critical for stability, fairness, and
effective governance of AI-mediated environments.

</details>
